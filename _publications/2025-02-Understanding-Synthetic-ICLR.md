---
title: "Towards a Theoretical Understanding of Synthetic Data in LLM Post-Training: A Reverse-Bottleneck Perspective"
collection: Proceedings
excerpt: 'This paper explores the critical role of synthetic data in enhancing the post-training performance of large language models (LLMs) from a novel reverse-bottleneck perspective.'
date: February, 2025
venue: 'ICLR'
paperurl: 'https://arxiv.org/abs/2410.01720'
citation: 'Zeyu Gan, Yong Liu. Towards a Theoretical Understanding of Synthetic Data in LLM Post-Training: A Reverse-Bottleneck Perspective. In The Thirteenth International Conference on Learning Representations (ICLR), 2025.'
---
